#!/usr/bin/perl

use strict;
use lib "$ENV{GUS_HOME}/lib/perl";
use Getopt::Long;
use GUS::Supported::GusConfig;
use DBI;

$| = 1;

my ($gusConfigFile, $dropApiDB, $dropGUS, $create, $db, $allowFailures, $verbose);

&GetOptions("gusConfigFile=s" => \$gusConfigFile,
           "dropApiDB!" => \$dropApiDB,
           "dropGUS!" => \$dropGUS,
           "allowFailures!" => \$allowFailures,
           "create!" => \$create,
           "verbose!" => \$verbose,
           "db=s" => \$db);

my $x = $dropApiDB + $dropGUS + $create;
if (!$db || ($x != 1)) {
  die "

Install the ApiDB and ApiDBTuning schemas and the ApidDB patches to GUS, or uninstall them (or uninstall the GUS schemas)

usage: installApidbSchema --db database [--create | --dropApiDB | --dropGUS] [--gusConfigFile gus_config_file] [--allowFailures] [--verbose]

Caution: only use --allowFailures if you know what you are doing

create - creates the ApiDB and ApiDBTuning schemas and patches GUS.

dropApiDB - drops the ApiDB and ApiDBTuning schemas, and ApiDB patches to GUS.

dropGUS - drops the Core, DoTS, PROT, RAD, SRes, STUDY, TESS (and all VER) schemas

Log is printed to STDOUT

Verbose prints commands run to STDERR

";
}

my $d = 'GUS schema';
$d = 'ApiDB and ApiDBTuning schemas' if $dropApiDB;

if ($dropApiDB || $dropGUS) {
    print "\nYou are about to UNINSTALL the $d on:\n  $db\nType the name of the instance to confirm: ";
    my $confirm = <STDIN>;
    chomp $confirm;
    die "You did not correctly confirm the db instance\n" unless $db eq $confirm;
}

my $gusconfig = GUS::Supported::GusConfig->new($gusConfigFile);

my $login = $gusconfig->getDatabaseLogin();
my $password = $gusconfig->getDatabasePassword();


# PLEASE READ BEFORE ADDING TO @create
#
# The list is ordered according to these rules:
# first:  changes to GUS
# second: create ApidbTuning schema
# third:  create Apidb schema
# fourth: create tables within Apidb, in dependency order as needed
#
# This ordering helps ensure that when/if we drop, the dropping proceeds
# in the correct order, avoiding bogus failures from dropping what was
# not yet created.
#
# ALSO: if you are adding a create script for the Apidb schema
#       it is good practice to write a parallel drop script
#       so that if needed, the create can be manually reversed

my @create = qw(
               removeNullConstraintsFromSimilarityTables.sql
               createGusTuning.sql
               createApidbTuningSchema.sql
               createApidbUserDatasetsSchema.sql
               createTestTuningSchema.sql
               createApidbSchema.sql
               createChebiSchema.sql
               createHmdbSchema.sql
               createEdaSchema.sql
               createHMDBTables.sql
	       createAnalysisMethodInvocation.sql
	       createDatasource.sql
	       createDbLinks.sql
               createSnpTables.sql
	       createGeneInteractionTables.sql
	       createGeneFeatureProduct.sql
	       createGeneFeatureName.sql
	       createOrthologGroup.sql
	       createPhylogeneticProfile.sql
	       createPhylogeneticTree.sql
	       createRelatedNaFeature.sql
	       createReportCache.sql
	       createSequenceAttributeTables.sql
	       createOrganism.sql
	       createStoredProcedures.sql
               createPivotProcedure.sql
	       createSyntenyTables.sql
	       createSpliceSiteFeature.sql
	       createPubChemSubstance.sql
	       createPubChemCompound.sql
	       createDbRefCompound.sql
	       createOldAnnotation.sql
	       createOldCodingSequence.sql
	       createTuningManager.sql
	       createWorkflow.sql
	       createIntronJunction.sql
	       createNAFeatureHaploblock.sql
               createBlatProteinAlignment.sql
	       createGFF3Table.sql
	       createEcNumberGenus.sql
	       createSpliceSiteGenes.sql
	       createPolyAGenes.sql
               createMassSpecSummary.sql
               createCompoundMassSpec.sql
               createPathwayTables.sql
               createTranscriptProduct.sql
               createIsolateGPS.sql
               createPhenotype.sql
               createNAFeaturePhenotype.sql
               createPhenotypeScore.sql
               createPhenotypeMutants.sql
               createPhenotypeGrowthRate.sql
               createHaplotypeResult.sql
               createOntologyTermResult.sql
               createSubjectResult.sql
               createSeqEdit.sql
               createWHOStandards.sql
               createLOPITResults.sql
               createWGCNAResults.sql
               createWGCNAModuleEigengeneResults.sql
               createNAFeatureMetaCycle.sql
               createCNVTables.sql
               createRflpTables.sql
               createNAFeatureImage.sql
               createSequenceTaxon.sql
               createFeatureLocation.sql
               createCrisprPhenotype.sql 
               createGoSubset.sql
               createUserDatasetCoreTables.sql
               createUserDatasetTypeTables.sql
               createDatabaseTableMapping.sql
               createEdaUdSchema.sql
               createEntityGraphTables.sql
               createEdaUdModifications.sql
               createExternalResourceUrl.sql
               createAGPPiece.sql
	     );


# drop GUS first, then ApidbTuning, then Apidb (reverse of order they were created in).
# for GUS, we only drop the tuning indexes, as the other GUS changes don't
# need to be reversed.  The trick here is to order these to avoid failures
my @delete = qw( restoreNullConstraintsFromSimilarityTables.sql
                 dropGusTuning.sql
      	         dropDbLinks.sql
                 dropTestTuningSchema.sql
                 dropApidbTuningSchema.sql
                 dropApidbUserDatasetsSchema.sql
                 dropApidbSchema.sql
			     dropChebiSchema.sql
				 dropHMDBSchema.sql
                 dropExternalResourceUrl.sql
               );

if ($create) {
  for my $sql (@create) {
     print STDOUT "\n==============================================================\n";
     print STDOUT "$sql\n";     
     print STDOUT "==============================================================\n";
     
     my @sqlplusParamValues;
     if($sql eq 'createEntityGraphTables.sql') {
       $sqlplusParamValues[0] = "EDA";
       &runSql($login, $password, $db, $sql, @sqlplusParamValues);

       $sqlplusParamValues[0] = "EDA_UD";
       &runSql($login, $password, $db, $sql, @sqlplusParamValues);
     }

     else {
       &runSql($login, $password, $db, $sql, @sqlplusParamValues);
     }


  }

} elsif ($dropApiDB) {
  &dropSchemaSetTables($login, $password, $db, "'APIDB','APIDBTUNING','APIDBUSERDATASETS','CHEBI','HMDB', 'EDA', 'EDA_UD'");

} elsif ($dropGUS) {
  &dropSchemaSet($login, $password, $db,
                 "'CORE','DOTS','MODEL','PLATFORM','RESULTS','SRES','STUDY','COREVER','DOTSVER','MODELVER','PLATFORMVER','RESULTSVER','SRESVER','STUDYVER'");

}

print STDERR "\nDone.\n";

sub runSql {
  my ($login, $password, $db, $file, @sqlplusParamValues) = @_;

  my $fullFile = "$ENV{GUS_HOME}/lib/sql/apidbschema/$file";

  -e $fullFile || die "File .sql file '$fullFile' does not exist\n";

  my $tmpFile = "/tmp/$file.$$";  # append the process id
  unlink($tmpFile);  # in case of a old one
  my $cmd;
  if (!$allowFailures) {
      $cmd = "echo 'whenever sqlerror exit sql.sqlcode;' > $tmpFile";
      runCmd($cmd, $tmpFile);
  }
  $cmd = "echo 'set echo on;' >> $tmpFile";
  runCmd($cmd, $tmpFile);

  $cmd = "cat $fullFile >> $tmpFile";
  runCmd($cmd, $tmpFile);

  my $sqlplusParamValuesString = join(" ", @sqlplusParamValues);
  $cmd = "sqlplus $login\@$db/$password \@$tmpFile $sqlplusParamValuesString";
  print STDOUT "\n==============================================================\n";
  print STDOUT "Running $tmpFile\n";
  print STDOUT "==============================================================\n";

  runCmd($cmd, $tmpFile);
  unlink($tmpFile);
}

sub runCmd {
    my ($cmd, $tmpFile) = @_;
    print STDERR "\nrunning command: $cmd\n" if $verbose;
    system($cmd);
    my $status = $? >> 8;
    if ($status) {
      unlink($tmpFile);
      die "Failed with status '$status running cmd: \n$cmd'\n";
    }
}

sub dropSchemaSetTables {
  my ($login, $password, $db, $schemaSet) = @_;

  my $dsn = "dbi:Oracle:" . $db;
  my $dbh = DBI->connect(
                $dsn,
                $login,
                $password,
                { PrintError => 1, RaiseError => 0}
                ) or die "Can't connect to the database: $DBI::errstr\n";

  print STDERR "\nfixing to drop objectss in schema set \"$schemaSet\"\n" if $verbose;

  # drop everything
  my $stmt = $dbh->prepare(<<SQL);
    select 'drop ' || object_type || ' ' || owner || '.' || object_name
           || decode(object_type, 'TABLE', ' CASCADE CONSTRAINTS', '')
    from all_objects
    where owner in ($schemaSet)
      and object_type not in ('INDEX', 'TRIGGER', 'TYPE BODY')
SQL

  my $objectsToDrop = 1;

  while ($objectsToDrop) {
    $stmt->execute()
      or addErrorLog("\n" . $dbh->errstr . "\n");

    if (my ($dropStmtSql) = $stmt->fetchrow_array()) {
      print STDERR "running statement: $dropStmtSql\n" if $verbose;
      $dbh->do($dropStmtSql) or die "Can't fetch a drop statement: $DBI::errstr\n";
    } else {
      $objectsToDrop = 0;
    }
  }

}

sub dropSchemaSet {
  my ($login, $password, $db, $schemaSet) = @_;

  my $dsn = "dbi:Oracle:" . $db;
  my $dbh = DBI->connect(
                $dsn,
                $login,
                $password,
                { PrintError => 1, RaiseError => 0}
                ) or die "Can't connect to the database: $DBI::errstr\n";

  print STDERR "\nfixing to drop schemas in set \"$schemaSet\"\n" if $verbose;

  my $stmt = $dbh->prepare(<<SQL);
    select 'drop user ' || username || ' cascade'
    from all_users
    where username in ($schemaSet)
SQL

  $stmt->execute()
    or addErrorLog("\n" . $dbh->errstr . "\n");

  while (my ($dropStmtSql) = $stmt->fetchrow_array()) {
    print STDERR "\nrunning statement: $dropStmtSql\n" if $verbose;
    $dbh->do($dropStmtSql) or die "Can't fetch a drop statement: $DBI::errstr\n";
  }

}
